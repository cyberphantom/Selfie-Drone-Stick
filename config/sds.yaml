# Environment Parameters
input_frame_size:
  w: 640
  h: 360

max_incl: 8.0 # Max space width in meters

alt_TH:
  max: 5.0   # in meters
  min: 0.5

yaw_TH:
  min: -1.55
  max: 1.55

ratio_TH:
  min: 0.00
  max: 0.24

init_state:
  px: 0.0
  py: 0.0
  pz: 0.0
  ox: 0.0
  oy: 0.0
  oz: 0.0
  ow: 0.0

goal:
    yaw: 0.0
    cx: 320.0
    cy: 180.0
    ratio: 0.1

# Training Algortihm Parameters
training: True
resume: False
resume_ep: 40400
output_graph: True

gamma: 0.97 # Higher gamma = smaller discount means care more about long term reward
            # Small gamma = High discount means care more about short term reward.
alpha: 0.1

explore_start: 1.0 # 1.0
explore_stop: 0.005

d_rate: 0.00002 # TODO: change 0.00005

batch_size: 256 # TODO: enlarge

tauTH: 250

learning_rate: 2e-4
memory_size: 102400

# Reward parameters
nactions: 81 # Discrete action Space
speed: 0.25   # in m/s
stepsTH: 64 # Each step = 0.25ms => 5 sec
episodesTH: 102400000
step_duration: 0.15  # in seconds
stack_size: 4
ob_size: 8

obs_trails: 2.0
failed_sec_detect_TH: 8
